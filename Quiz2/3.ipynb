{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is  iris\n"
     ]
    }
   ],
   "source": [
    "dataset_type = input('Enter iris for the Iris dataset and cancer for the Breast Cancer dataset ')\n",
    "if dataset_type.lower() == 'iris': \n",
    "  the_data = load_iris() #get the data from sklearn\n",
    "elif dataset_type.lower() == 'cancer': \n",
    "  the_data = load_breast_cancer() #get the data from sklearn\n",
    "elif dataset_type.lower() == 'digits':\n",
    "  the_data = load_digits() #get the data from sklearn\n",
    "else: \n",
    "  print('Invalid dataset type')\n",
    "  exit()\n",
    "print('The dataset is ', dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_type(name):\n",
    "    if dataset_type.lower() == 'iris':\n",
    "        feature = the_data.data\n",
    "        target = the_data.target\n",
    "    elif dataset_type.lower() == 'cancer':\n",
    "        feature = the_data.data\n",
    "        target = the_data.target\n",
    "    elif dataset_type.lower() == 'digits':\n",
    "        feature = the_data.data\n",
    "        target = the_data.target\n",
    "    return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(name, feature, target):\n",
    "    feature, target = check_type(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def Gaussian_NB(name, feature, target):\n",
    "    training_features, testing_features, training_labels, testing_labels = split_data(name, feature, target)\n",
    "    classifier = GaussianNB()\n",
    "    model = classifier.fit(training_features, training_labels)\n",
    "    # use the model obtained in previous step to predict labels for testing features\n",
    "    predicted_labels = model.predict(testing_features)\n",
    "    # evaluate the model\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy_percent = accuracy_score(testing_labels, predicted_labels) * 100\n",
    "    print(\"\\nThe \" + name +\" use GaussianNB Accuracy: %5.2f%%\\n\" % accuracy_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def best_K(name, feature, target):\n",
    "    training_features, testing_features, training_labels, testing_labels = split_data(name, feature, target)\n",
    "    neighbor_size = []\n",
    "    errors_list = []\n",
    "    best_k = 0\n",
    "    for k in range (2, 20): \n",
    "        classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "        model = classifier.fit(training_features,training_labels)  # or can also use:   predicted_labels = classifier.fit(train_features,train_labels) \n",
    "        predicted_labels = model.predict(testing_features)  #use the model obtained in previous step to predict labels for testing features\n",
    "        accuracy_percent = accuracy_score(testing_labels, predicted_labels) * 100\n",
    "        # Calculating the % Accuracy of the prediction. \n",
    "        print(\"Prediction Accuracy for k = %2d : %5.2f%%\" % (k, accuracy_percent)) #%% escapes the formatting % to print '%'\n",
    "        neighbor_size.append(k)\n",
    "        errors_list.append(101-accuracy_percent)\n",
    "        if min(errors_list):\n",
    "            best_k = neighbor_size[errors_list.index(min(errors_list))]\n",
    "    #print (\" K = \", neighbor_size, \"\\n\", \"Errors = \", errors_list)\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def Knn(name, k, feature, target):\n",
    "    training_features, testing_features, training_labels, testing_labels = split_data(name, feature, target)\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    model = classifier.fit(training_features, training_labels)\n",
    "    # use the model obtained in previous step to predict labels for testing features\n",
    "    predicted_labels = model.predict(testing_features)\n",
    "    # evaluate the model\n",
    "    accuracy_percent = accuracy_score(testing_labels, predicted_labels) * 100\n",
    "    print(\"\\nThe \" + name +\" use KNN Accuracy: %5.2f%%\" % accuracy_percent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The iris use GaussianNB Accuracy: 96.67%\n",
      "\n",
      "Prediction Accuracy for k =  2 : 96.67%\n",
      "Prediction Accuracy for k =  3 : 96.67%\n",
      "Prediction Accuracy for k =  4 : 100.00%\n",
      "Prediction Accuracy for k =  5 : 96.67%\n",
      "Prediction Accuracy for k =  6 : 100.00%\n",
      "Prediction Accuracy for k =  7 : 100.00%\n",
      "Prediction Accuracy for k =  8 : 100.00%\n",
      "Prediction Accuracy for k =  9 : 100.00%\n",
      "Prediction Accuracy for k = 10 : 100.00%\n",
      "Prediction Accuracy for k = 11 : 100.00%\n",
      "Prediction Accuracy for k = 12 : 100.00%\n",
      "Prediction Accuracy for k = 13 : 100.00%\n",
      "Prediction Accuracy for k = 14 : 100.00%\n",
      "Prediction Accuracy for k = 15 : 100.00%\n",
      "Prediction Accuracy for k = 16 : 100.00%\n",
      "Prediction Accuracy for k = 17 : 100.00%\n",
      "Prediction Accuracy for k = 18 : 100.00%\n",
      "Prediction Accuracy for k = 19 : 100.00%\n",
      "\n",
      "The iris use KNN Accuracy: 100.00%\n",
      "\n",
      "The best K is  4\n"
     ]
    }
   ],
   "source": [
    "feature, target = check_type(dataset_type)\n",
    "Gaussian_NB(dataset_type, feature, target)\n",
    "k = best_K(dataset_type, feature, target)\n",
    "Knn(dataset_type, k, feature, target)\n",
    "print(\"\\nThe best K is \", k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
